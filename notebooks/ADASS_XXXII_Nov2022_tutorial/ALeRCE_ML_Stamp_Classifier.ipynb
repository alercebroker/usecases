{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xH-PBRgmDTIX"
   },
   "source": [
    "# ALeRCE Stamp Classifier notebook\n",
    "\n",
    "```Author: Rodrigo Carrasco-Davis, modifications: Ignacio Reyes, Francisco Förster. Last updated: 20221104```\n",
    "\n",
    "For more information about the ALeRCE broker, please visit http://alerce.science/, or take a look to our presentation paper: F. Förster et al 2021 AJ 161 242 (https://doi.org/10.3847/1538-3881/abe9bc).\n",
    "\n",
    "This notebook uses the ALeRCE API through our Python client, which can be installed with `pip install alerce`. To get the newest version you can clone and install https://github.com/alercebroker/alerce_client (use the command `python -m pip install -e .` to install). The documentation is available at https://alerce.readthedocs.io/en/latest/index.html\n",
    "\n",
    "We recommend that you run this tutorial notebook from colab in this [link](https://colab.research.google.com/github/alercebroker/usecases/blob/master/notebooks/ADASS_XXXII_Nov2022_tutorial/ALeRCE_ML_Stamp_Classifier.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MF77tM-aDTIa"
   },
   "source": [
    "# Table of contents:\n",
    "* [Introduction](#intro)\n",
    "    * [Training data](#training_data) \n",
    "    * [Convolutional neural network architecture](#CNN)\n",
    "    * [Classification results](#Results)\n",
    "* [ALeRCE frontend and Supernova Hunter](#Front)\n",
    "* [Requirements](#req)\n",
    "* [ALeRCE client](#client)\n",
    "    * [Plotting light curves](#plot_lc)\n",
    "    * [Retrieve classified alerts](#get_alerts)\n",
    "    * [Plot some examples](#examples)\n",
    "    * [Get a sequence of stamps](#stamp_series)\n",
    "    * [Get spatial distribution](#spatial_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGyn1E3RDTIg"
   },
   "source": [
    "# Introduction <a class=\"anchor\" id=\"intro\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vEA3sHWADTIl"
   },
   "source": [
    "In this notebook, we will explore the results of the ALeRCE stamp classifier, explained in **R. Carrasco-Davis et al 2021 AJ 162 231 (https://doi.org/10.3847/1538-3881/ac0ef1)**, which is based on a convolutional neural network (CNN) that uses the images and metadata of the first alert only as input. The stamp classifier uses the first alert to quickly discriminate between active galactic nuclei (AGN), supernovae(SNe), variable stars (VS), asteroids, and bogus alerts. The predictions of the classifier are used to sort the alerts by their probability of being a supernova so an astronomer can see them in the [Supernova Hunter](https://snhunter.alerce.online/) web interface, to then report the candidates to TNS. We also have a light curve based classifier **(P. Sánchez-Sáez et al 2021 AJ 161 141; https://doi.org/10.3847/1538-3881/abd5c1)**, which classifies objects based on their light curve. The purpose of this classifier is to provide a more refined classification starting with at least 6 detections in a given band. For more information please check the AGN, Variable S\n",
    "\n",
    "### Training Data: <a class=\"anchor\" id=\"training_data\"></a>\n",
    "Using the labeled set from P. Sánchez-Sáez et al 2021 (The ALeRCE light curve classifier paper), we gathered 52,244 first alerts to build our training set. The number of samples of AGN, SN, VS, asteroid, and bogus are 14,966(29%), 1620 (3%), 14,996 (29%), 9899 (19%), and 10,763(20%) respectively. The images in the alert are the science, template and difference image. We noticed each of these classes can be classified fast since they present specific properties that can be found in the information of the first alert:\n",
    "\n",
    "+ AGN: Being stochastically variable objects, an alert generated by an AGN should have flux from the source in both the reference and science stamps. Considering this feature alone, it is difficul. t to discriminate AGNs from other variable sources. Nevertheless, AGNs should lie at the centers of their host galaxies, or appear as (quasi-)stellar objects, in relatively lower stellar density fields. Thus, a change in flux will appear as a variable source, which may lie at the center of a galaxy, or even when the galaxy is not visible they tend to be in lower stellar density fields. In these cases, the alert is likely to be triggered by an AGN. In addition, AGNs are commonly found outside the Galactic plane.\n",
    "    \n",
    "+ Supernovae (SNe): An alert generated by a SN should appear as a change in flux where no unresolved sources were present. These transients tend to appear near their host galaxies, and their location should be consistent with the underlying host stellar population distribution (e.g., a SN will have a higher probability of arising from a location aligned with the disk than perpendicular to it). As such, most SN detections exhibit a visible host galaxy in both the science and reference stamps, with the flux from the SN arising only in the science and difference images. SN candidates tend to appear outside the Galactic plane due to occlusion.\n",
    "    \n",
    "+ Variable Stars (VS): The flux coming from variable stars usually appears in both the reference and science stamps. With ZTF's sensitivity, variable stars can be detected within the Milky Way or the Local Group, and thus the alert will typically not be associated with a visible host galaxy in the stamp, but rather with other point-like sources. In addition, such alerts will have a higher probability of residing at lower Galactic latitudes and in crowded fields with multiple point sources within the stamps, given the high concentration of stars in the disk and bulge of our Galaxy.\n",
    "\n",
    "+ Asteroids: Alerts from moving Solar-system objects will appear only one time at a given position, and thus will show flux only in the science and difference images. Depending on their distance and speed, they may appear elongated in the direction of motion. In addition, such alerts should have a higher probability of residing near the ecliptic.\n",
    "    \n",
    "+ Bogus alerts: Camera and telescope optics effects, such as saturated pixels at the centers of bright sources, bad columns, hot pixels, astrometric misalignment in the subtraction to compute the difference image, unbaffled internal reflections, etc., can produce bogus alerts with no interesting real source. Bogus alerts are characterized by the presence of NaN pixels due to saturation, single or multiple bright pixels with little or no spatial extension (i.e., smaller than the telescope point spread function (PSF) and nightly seeing), or lines with high or low pixel values that extend over a large portion of the stamp (hot or cold columns/rows).\n",
    "\n",
    "<img src=\"figures/ml/class_samples.png\" width=90% />\n",
    "\n",
    "Here we show examples of the five classes that are to be discriminated by using only the first detection. For each class, the triplet of images in each row are science, reference and difference images from left to right. Each row corresponds to a different candidate. The images are cropped at the center resulting in 21x21 images, and normalized. Further details about the pre-processing of the images is explained in Carrasco-Davis et al 2021.\n",
    "\n",
    "### Convolutional neural network architecture: <a class=\"anchor\" id=\"CNN\"></a>\n",
    "\n",
    "<table><tr><td><img src=\"figures/ml/cnn_architecture.png\"></td><td><img src=\"colab/figures/ml/cnn_table.png\"></td></tr></table>\n",
    "\n",
    "The Figure on the left represent the stamp classifier. The box Convolutional Layers refers to those described in the Table at the right side, from the first convolutional layer to the last pooling layer. For each sample, the science, reference and difference images are concatenated in the channel dimension, obtaining an image input of dimension $21 \\times 21 \\times 3$. For each sample within the sampled batch, rotated versions are generated and fed to the CNN. After the first dense layer, the dense vectors of each the rotated version for the same objects are averaged. The metadata features pass through a batch normalization layer, the output of which is concatenated with the cyclic pooling output. Then, the concatenation goes through 2 fully connected layers, and finally a softmax function is applied to estimate the output probabilities. For the convolutional layers, the parameters shown in the table at the right are the filter dimensions and number of output channels. All the convolutional layers and fully connected layers have a Recified Linear Unit (ReLU) activation function (except for the last fully connected one that has a softmax output).\n",
    "\n",
    "When the CNN model is trained using cross-entropy as the loss function to be minimized, the classification confidence of the model is very high, resulting in a distribution of output probabilities with saturated values of 0s and 1s without populating the values in between, even for wrong classifications. In this case there is no insight of certainty (relative probabilities between classes) of the prediction because most estimated probabilities for each class were either 0 or 1. In order to provide more granularity to the astronomers who revise SN candidates reported by the model to later request follow-up observing time, we added the entropy of the predicted probabilities of the models as a regularization term, to be maximized during training. By maximizing the entropy of the output probabilities, we penalize predictions with high confidence, in order to get better insight in cases where the stamps seem equally likely to belong to more than one class. The loss function $\\mathcal{L}$ per sample is as follows:\n",
    "\n",
    "$$    \\mathcal{L} = \\underbrace{-\\sum_{c=1}^{N}y_{c}\\log{(\\hat{y}_{c})}}_{\\text{cross-entropy}} + \\underbrace{\\beta \\sum_{c=1}^{N}\\hat{y}_{c}\\log{(\\hat{y}_{c})}}_{\\text{entropy regularization}},$$\n",
    "where $N$ is the number of classes, $y_{c}$ is the one-hot encoding label (a value of 1 in the corresponding index of class, and 0 for the rest)  indexed by $c$, $\\hat{y}_{c}$ is the model prediction for class $c$, and $\\beta$ controls the regularization term in the loss function.\n",
    "\n",
    "### Clasification results: <a class=\"anchor\" id=\"Results\"></a>\n",
    "\n",
    "<table><tr><td><img src=\"figures/ml/cm.png\"></td><td><img src=\"colab/figures/ml/betas.png\"></td></tr></table>\n",
    "\n",
    "In the left image we show the confusion matrix in the test set for the proposed model. We use accuracy to compare models since the validation and test sets are balanced; achieving $0.95 \\pm 0.005$ in the validation set and $0.941 \\pm 0.004$ in the test set. To compute the confusion matrix we run five realizations of the mentioned model. With our five class model, we recover $87 \\pm 1\\%$ of the SNe, with only $5 \\pm 2\\%$ of false positives. By inspecting the predictions made by our model for each SN sample in the test set, we found that the results are in agreement with our initial expectations regarding the class discrimination described in the Training Data section. It is worth highlighting that the results of our model are achieved by using **the first alert only**.\n",
    "\n",
    "In the right image, we show the probability distribution for each of the classes in the training set, for different values of the regularization constant $\\beta=\\{ 0, 0.5, 1.0 \\}$. For the model without regularization ($\\beta = 0$ shown on the top plot), the probability distribution saturates to 1 or 0. Increasing $\\beta$ to 0.5 or 1.0 decreases the saturation and spreads the distribution of predictions made by the model (mid and bottom plots). In the case of $\\beta=0$, the predictions are mostly saturated around 0 or 1 for the SN, VS, Asteroids and Bogus alert classes, creating difficulties to identify stamps that seem equally likely to belong to more than one class, because every sample is mapped to similar levels of high certainty. As the value of $\\beta$ increases, the saturation of predicted values decreases, spreading the predicted probability distributions and emphasizing the different levels of certainty between predictions of different samples. The use of regularization to find noticeable differences in the predicted probabilities are helpful to experts for evaluating the output of the classifier, gaining better insight into how reliable the classifications are.\n",
    "\n",
    "# ALeRCE frontend and Supernova Hunter <a class=\"anchor\" id=\"Front\"></a>\n",
    "\n",
    "The [Supernova Hunter](https://snhunter.alerce.online/) is a visualization tool that allows the user to inspect SN candidates classified by the model in real time, in order to select good targets for follow-up observations.\n",
    "\n",
    "<img src=\"figures/ml/sn_hunter.png\" width=90% />\n",
    "\n",
    "On the bottom left side, the location of each candidate in sky coordinates with respect to the Galactic plane and the ecliptic are depicted. On the bottom right side, a selection of the top candidates is listed, initially ordered by SN probability score from the stamp classifier. The list of candidates can be sorted by other parameters, and updated/refreshed to include newly ingested alerts. On the top left side, the SN candidate ID is shown as a clickable link to the [ALeRCE frontend](https://alerce.online/object/ZTF20abpvolc), with relevant metadata such as radec coordinates, magnitude, date, etc. At the bottom there are links to other sources of information, including ALeRCE, NED, TNS, and the Simbad Astronomical Database. In the middle of the figure there is a colored image from Aladin. On the top right side, the stamps of the first detection are shown, along with buttons for reporting the candidate as eventual bogus or as a possible SN.\n",
    "\n",
    "<img src=\"figures/ml/alerce_frontend.png\" width=90% />\n",
    "\n",
    "When the candidate is inspected using the [ALeRCE frontend](https://alerce.online/object/ZTF20abpvolc), the full prediction of classes by the stamp classifier is shown at the bottom in addition to the full information of the light curve available, metadata, cross matches, etc. When the light curve of the object has six or more points in one of the bands, it is classified by the light curve classifier (Sánchez-Sáez et al. 2021), with the prediction also available in the ALeRCE frontend with a more complex taxonomy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ClWPQ1efDTIp"
   },
   "source": [
    "# Requirements <a class=\"anchor\" id=\"req\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T14:59:40.678780Z",
     "start_time": "2022-11-04T14:59:39.856577Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "qLP7BrH-DTIr",
    "outputId": "2c06072c-549e-4cd2-abeb-70dfa52bff84"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.time import Time\n",
    "import ephem\n",
    "import astropy.units as units\n",
    "from astropy.coordinates import SkyCoord\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import pickle\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2NwyVhPKDTI9"
   },
   "source": [
    "# ALeRCE client <a class=\"anchor\" id=\"client\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BXTYA_kgDTI_"
   },
   "source": [
    "Install and import the ALeRCE Python client with `pip install alerce`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T14:44:46.474553Z",
     "start_time": "2022-10-27T14:44:43.970608Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "colab_type": "code",
    "id": "YhPV-G1UDTJA",
    "outputId": "3ab1761b-3b0b-4fc7-d526-dccff931e08e"
   },
   "outputs": [],
   "source": [
    "!pip install alerce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T14:59:47.635002Z",
     "start_time": "2022-11-04T14:59:47.602572Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "u3qKnzR-ESXu"
   },
   "outputs": [],
   "source": [
    "from alerce.core import Alerce\n",
    "client = Alerce()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9O9f_xhwDTJL"
   },
   "source": [
    "### Plotting light curves <a class=\"anchor\" id=\"plot_lc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3RF3FetfDTJM"
   },
   "source": [
    "We will create a simple function that plots the light curve given an object id (oid), a dataframe with detections and a dataframe with non detections. This function will be used to plot light curves of some objects predicted by the stamp classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T14:59:49.558203Z",
     "start_time": "2022-11-04T14:59:49.543437Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "q605MT4iDTJO"
   },
   "outputs": [],
   "source": [
    "def plotLC(oid, SN_det, SN_nondet):\n",
    "    \n",
    "    colors = {1: '#56E03A', 2: '#D42F4B'} \n",
    "    fig, ax = plt.subplots(figsize = (14, 7))\n",
    "    fig.set_facecolor('white')\n",
    "    labels = {1: 'g', 2: 'r'}\n",
    "    markers = {1: 'o', 2: 's'}\n",
    "    sizes = {1: 30, 2: 60}\n",
    "    \n",
    "    # loop the passbands\n",
    "    for fid in [1, 2]:\n",
    "        \n",
    "        # plot detections if available\n",
    "        mask = SN_det.fid == fid\n",
    "        if np.sum(mask) > 0:\n",
    "            # note that the detections index is candid and that we are plotting the psf corrected magnitudes\n",
    "            ax.errorbar(SN_det[mask].mjd, SN_det[mask].magpsf, \n",
    "                yerr = SN_det[mask].sigmapsf, c=colors[fid], label=labels[fid], marker=markers[fid])\n",
    "        \n",
    "        # plot non detections if available\n",
    "        if len(SN_nondet) != 0:\n",
    "            mask = (SN_nondet.fid == fid) & (SN_nondet.diffmaglim > -900)\n",
    "            if np.sum(mask) > 0:     \n",
    "                # non detections index is mjd\n",
    "                ax.scatter(SN_nondet[mask].mjd, SN_nondet[mask].diffmaglim, c=colors[fid], alpha = 0.5,\n",
    "                    marker='v', label=\"lim.mag. %s\" % labels[fid], s=sizes[fid])\n",
    "\n",
    "    ax.set_title(oid)\n",
    "    ax.set_xlabel(\"MJD\")\n",
    "    ax.set_ylabel(\"Apparent magnitude\")\n",
    "    ax.legend()\n",
    "    ax.set_ylim(ax.get_ylim()[::-1])\n",
    "\n",
    "def getObjectData(oid, doLC=False, dostamp=False):\n",
    "\n",
    "    results = {\"oid\": oid}\n",
    "        \n",
    "    # query detections\n",
    "    SN_det = client.query_detections(oid, format='pandas')\n",
    "    SN_det = SN_det.sort_values(\"mjd\")\n",
    "    results[\"lc_det\"] = SN_det\n",
    "        \n",
    "    # query non detections\n",
    "    SN_nondet = client.query_non_detections(oid, format='pandas')\n",
    "    if len(SN_nondet)!=0:\n",
    "        SN_nondet = SN_nondet.sort_values(\"mjd\")\n",
    "        results[\"lc_nondet\"] = SN_nondet\n",
    "    \n",
    "    # plot the LC\n",
    "    if doLC:\n",
    "        plotLC(oid, SN_det, SN_nondet)\n",
    "        \n",
    "    # show the first image stamp\n",
    "    if dostamp:\n",
    "        candid = results[\"lc_det\"].loc[results[\"lc_det\"].has_stamp].candid.min()\n",
    "        stamps = client.get_stamps(oid, candid)\n",
    "        science, ref, difference = stamps[0].data, stamps[1].data, stamps[2].data\n",
    "        fig, ax = plt.subplots(ncols=3, figsize=(12, 6))\n",
    "        fig.set_facecolor('white')\n",
    "        for idx, im in enumerate([np.arcsinh(science), np.arcsinh(ref), difference]):\n",
    "            ax[idx].imshow(im, cmap='viridis') # Log scale for visualization\n",
    "            ax[idx].axes.get_xaxis().set_visible(False)\n",
    "            ax[idx].axes.get_yaxis().set_visible(False)\n",
    "        ax[0].set_title(\"oid: %s, candid: %s (science, reference and difference)\" % (oid, candid), loc='left')\n",
    "        fig.subplots_adjust(wspace = 0, hspace = 0)\n",
    "        \n",
    "    # return data\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdG09XfyDTJX"
   },
   "source": [
    "# Classified Alerts <a class=\"anchor\" id=\"get_alerts\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7KrbpSvADTJZ"
   },
   "source": [
    "### Get objects per class\n",
    "Here, we build a function that uses the ALeRCE client to query objects according to the predictions of the stamp classifier. In order to select the classifier, we define the query in terms of the classifier name, corresponding class and their minimum probability, the classes are the following strings:\n",
    "+ \"AGN\": Active Galactic Nuclei\n",
    "+ \"SN\": Supernova\n",
    "+ \"VS\": Variable star\n",
    "+ \"Asteroid\"\n",
    "+ \"Bogus\"\n",
    "\n",
    "Using the ALeRCE client we can select the min and max number of observations per object, also sort them by firstmjd, number of observations (ndet), probability of the selected class, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T15:56:48.131047Z",
     "start_time": "2022-11-04T15:56:48.127491Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WkIHB8G7DTJb"
   },
   "outputs": [],
   "source": [
    "def get_objects_per_class(classearly=\"SN\", pclassearly=0.8, n_objects=100):\n",
    "\n",
    "    min_firstmjd = Time(\"2022-06-01T00:00:00\", format=\"isot\", scale=\"utc\").mjd\n",
    "\n",
    "    objects = client.query_objects(classifier=\"stamp_classifier\",\n",
    "                                   class_name=classearly,\n",
    "                                   #classifier_version=\"stamp_classifier_1.0.4\",\n",
    "                                   probability=pclassearly,\n",
    "                                   ranking=1,\n",
    "                                   #ndet=[1, 50],\n",
    "                                   #order_by=\"probability\",\n",
    "                                   #order_mode=\"DESC\",\n",
    "                                   count=False,\n",
    "                                   first_mjd=[min_firstmjd, None],\n",
    "                                   page_size=n_objects, \n",
    "                                   format='pandas')\n",
    "    print(objects.shape)\n",
    "    objects.head()\n",
    "    objects.set_index(\"oid\", inplace=True)\n",
    "    objects.sort_values(by=\"ndet\", inplace=True, ascending=False)\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zt3Vd39EDTJm"
   },
   "source": [
    "The previous function returns a pandas dataframe with a list of objects by their ZTF oid as index, and relevant information in their columns as we will see next.\n",
    "Now, let's query some objects for each of the classes available from the stamp classifier. Here, we are querying a few thousands of objects from the ALeRCE database. We will also sort the classes by ascending number of observations in the cases of bogus and asteroids in order to get a clean example. AGNs, VS and SNe are sorted in descending order of number of observations to better appreciate the light curves for each of these classes.\n",
    "\n",
    "**This query will take a few seconds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T15:58:10.088558Z",
     "start_time": "2022-11-04T15:56:51.140100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "colab_type": "code",
    "id": "0cQVzzuuDTJn",
    "outputId": "d341b176-5788-40cb-a82b-87304c74b18b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_objects = 2000 # Objects per class to query\n",
    "early_classes = [\"AGN\", \"SN\", \"VS\", \"asteroid\", \"bogus\"] # Class identifiers to query objects\n",
    "objects = {} # Initialize dictionary to use the results per class\n",
    "min_nobs = 1\n",
    "for i, cl in enumerate(early_classes):\n",
    "    print(cl)\n",
    "    objects[cl] = get_objects_per_class(classearly=cl, n_objects=n_objects)\n",
    "    if i==0:\n",
    "        print(\"Result of a query using the ALeRCE client\")\n",
    "        display(objects[cl].head())\n",
    "        print(\"Columns available\", objects[cl].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v0HqPqBUDTJv"
   },
   "source": [
    "# Plot some examples per class <a class=\"anchor\" id=\"examples\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_n_0DSlZDTJw"
   },
   "source": [
    "Now we have a dataframe per class resulting from our queries. The following function is just to simplify the inspection of candidates by printing the URL to the ALeRCE frontend, and call the getObjectData function done previously with the flags doLC and dostamp True to plot everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T15:58:10.325781Z",
     "start_time": "2022-11-04T15:58:10.323725Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "TuuIkmzkDTJx"
   },
   "outputs": [],
   "source": [
    "def plot_some_LC(df, n_examples=3):\n",
    "    for i in range(n_examples):\n",
    "        object_id = df.iloc[i].name\n",
    "        print(f\"https://alerce.online/object/{object_id}\")\n",
    "        getObjectData(object_id, doLC=True, dostamp=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T15:59:34.586381Z",
     "start_time": "2022-11-04T15:59:15.729813Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ArPThOBiDTJ7",
    "outputId": "021aa6c0-b609-4a7e-f45b-38a2869aa8f7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cl, df in objects.items():\n",
    "    print(\"######### \"+ cl + \" class #########\")\n",
    "    print(cl)\n",
    "    display(df)\n",
    "    if cl in [\"asteroid\", \"bogus\"]: # Just to have well classified samples to show\n",
    "        df.sort_values(by=\"ndet\", inplace=True)\n",
    "    plot_some_LC(df, n_examples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qBnvOuBODTKD"
   },
   "source": [
    "The distribution of the number of detections per class can give us insights on how well the classifier is working. For instance, for AGNs, SNe, and VS, we expect to see more than one detection for these classes. The objects belonging to these classes and have one detection could be new objects or the ones visited only once, short transients, or errors in the classification. For asteroids and bogus class, we expect to have objects with one detection only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T15:59:52.346520Z",
     "start_time": "2022-11-04T15:59:51.841243Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "colab_type": "code",
    "id": "z8Br0Vo7DTKF",
    "outputId": "0952662e-1c7a-4111-e2ad-29ccaad2ac82"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(20, 8))\n",
    "fig.set_facecolor('white')\n",
    "bins = np.arange(0, 40)\n",
    "ax = ax.flatten()\n",
    "fontsize = 16\n",
    "\n",
    "# Concatenated dataframe with all the classes\n",
    "h, _ = np.histogram(pd.concat(list(objects.values()), axis=0).ndet, bins=bins, density=True)\n",
    "ax[0].bar(bins[:-1], h, label=\"all_data\")\n",
    "ax[0].set_title(\"all data\", fontsize=fontsize)\n",
    "ax[0].tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "ax[0].set_ylim([0, 1])\n",
    "\n",
    "for i, (cl, df) in enumerate(objects.items()):\n",
    "    # Histogram per class\n",
    "    h, bins = np.histogram(df.ndet, bins=bins, density=True)\n",
    "    ax[i+1].bar(bins[:-1], h, label=cl)\n",
    "    ax[i+1].set_title(cl, fontsize=fontsize)\n",
    "    ax[i+1].tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "    ax[i+1].set_ylim([0, 1])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZdic8cmDTKL"
   },
   "source": [
    "In our small sample we can see that most of the asteroids and bogus have only one detection, while AGNs, SNe and VS have a long tail of objects with more than one detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_BhSaYTcDTKM"
   },
   "source": [
    "# Get a sequence of stamps <a class=\"anchor\" id=\"stamp_series\"></a>\n",
    "\n",
    "In this section, we will implement a function to get a series of stamps from the alerts availables for a given object. The stamp classifier uses the first alert only, but in ALeRCE we are working to extend the stamp classifier to use a multi-stamp approach considering band g and r simultaneously. One example of this kind of classifier is the one presented in [Carrasco-Davis et al. 2019](https://iopscience.iop.org/article/10.1088/1538-3873/aaef12), where the stamps are processed by a convolutional neural network, to then use a recurrent neural network that can store previous inputs of the sequence of stamps. Then, in case you want to experiment with a sequence of stamps, here is an example:\n",
    "+ We first get the detections of an object using get_detection of the ALeRCE client\n",
    "+ Then we sort the values by mjd\n",
    "+ The resulting dataframe uses the candidate id as index, then we use the get_stamp function for each candidate to obtain their respective stamp\n",
    "+ We finally plot the stamps and return a list of stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T15:59:56.922822Z",
     "start_time": "2022-11-04T15:59:56.917934Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "RJqF95vgDTKO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_stamp_series(oid, n_stamps=5, show_stamps=False, show_LC=False):\n",
    "    band_labels = {1: 'g', 2: 'r'}\n",
    "    band_cmap = {\"g\": \"viridis\", \"r\": \"inferno\"}\n",
    "    object_det = client.query_detections(oid, format='pandas') # Get object detections\n",
    "    candids = object_det.loc[object_det.has_stamp]\n",
    "    object_det = object_det.iloc[:n_stamps] # Use n stamps only\n",
    "    candids = object_det.candid # Obtain the candidate id to use it in the get_stamp function\n",
    "    stamps = []\n",
    "    for c in candids:\n",
    "        candid_stamps = client.get_stamps(oid, candid=c)\n",
    "        stamps.append(candid_stamps) # Save the stamps in a list to return\n",
    "    \n",
    "    if show_LC:\n",
    "        getObjectData(oid, doLC=True, dostamp=False) # Plot the light curve of the object\n",
    "        \n",
    "    if show_stamps:\n",
    "        fig, ax = plt.subplots(3, n_stamps, figsize=(n_stamps*3, 10))\n",
    "        fig.set_facecolor('white')\n",
    "        for i, s in enumerate(stamps):\n",
    "            corresponding_band = band_labels[object_det.iloc[i].fid] # Check band\n",
    "            cmap = band_cmap[corresponding_band] # use a different cmap for each band\n",
    "            # The get_stamp function returns a list with three images \n",
    "            # (science, reference and difference) in hdu format. Using .data we get the numpy array.\n",
    "            science, ref, difference = s[0].data, s[1].data, s[2].data \n",
    "            ax[0, i].imshow(np.arcsinh(science), cmap=cmap) # Log scale for visualization\n",
    "            ax[1, i].imshow(np.arcsinh(ref), cmap=cmap)\n",
    "            ax[2, i].imshow(difference, cmap=cmap)\n",
    "            title = \"MJD \" + str(np.round(object_det.iloc[i].mjd, 2)) + \", band: \"+corresponding_band\n",
    "            ax[0, i].set_title(title)\n",
    "        ax[0, 0].set_ylabel(\"Science\")\n",
    "        ax[1, 0].set_ylabel(\"Reference\")\n",
    "        ax[2, 0].set_ylabel(\"Difference\")\n",
    "        plt.show()\n",
    "    return object_det, stamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HmavR8z3DTKW"
   },
   "source": [
    "Let's use [ZTF19acftude](https://alerce.online/object/ZTF19acftude) since it has a very nice looking SN light curve and host galaxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T16:00:01.408376Z",
     "start_time": "2022-11-04T15:59:59.918969Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JsdGSUYEDTKZ",
    "outputId": "4e20fa7d-0794-437e-825d-ba00df84481e"
   },
   "outputs": [],
   "source": [
    "detections, stamps = get_stamp_series(oid=\"ZTF19acftude\", show_stamps=True, show_LC=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bE7eKWZ1DTKg"
   },
   "source": [
    "The detections dataframe contains important information regarding the specific properties measured at a given time for the same object. For instance, the measuring time in mjd, mean and std of the position in radec, the magnitude, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T16:00:03.581475Z",
     "start_time": "2022-11-04T16:00:03.568154Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "id": "cwEzdAVqDTKg",
    "outputId": "7ed8b9e6-9174-462a-e380-d61fcf5e3a4d"
   },
   "outputs": [],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T16:00:05.626935Z",
     "start_time": "2022-11-04T16:00:05.623833Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "0fnxWSZJDTKo",
    "outputId": "7f52b603-0369-46f2-f1a1-efd9b8f3ad64"
   },
   "outputs": [],
   "source": [
    "detections.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AqPXq9cnDTKx"
   },
   "source": [
    "# Get spatial distribution of predictions <a class=\"anchor\" id=\"spatial_distribution\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vRxqI7JbDTKy"
   },
   "source": [
    "One issue when training models in astronomy is the possible biases found in the training set. One of the problems we had at the beginning was the abundance of extragalactic objects predicted near the galactic plane. As mentioned in the Introduction, SNe and AGNs are less likely to be found near the galactic plane due to occlusion. We fixed this problem by adding some features to the CNN at the fully connected layers, one of the most important are the ecliptic and galactic coordinates, so let's see how they look like per class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eBZwcmcaDTK2"
   },
   "source": [
    "### Compute galactic and ecliptic coordinates\n",
    "We computed the coordinates from the meanra and mean dec using the ephem python package. Here (https://rhodesmill.org/pyephem/coordinates.html) there is a more detailed tutorial of how to use this transformation between coordinates. Now, we will take our dataframes and add ecliptic and galactic latitude and longitude as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T16:00:08.134233Z",
     "start_time": "2022-11-04T16:00:07.630175Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "XDs0a5zFDTK3"
   },
   "outputs": [],
   "source": [
    "def ecliptic_coordinates(df):\n",
    "    # Define the lambda function to be applied to each row of the dataframe\n",
    "    ecl = df.apply(lambda row: ephem.Ecliptic(ephem.Equatorial('%s' % (row.meanra / 15.),\n",
    "                                                               '%s' % row.meandec, epoch=ephem.J2000)), axis=1)\n",
    "    \n",
    "    # Apply the function to each row, the result is append as a new column\n",
    "    df[\"ecl_lat\"] = ecl.apply(lambda row: np.rad2deg(row.lat))\n",
    "    df[\"ecl_long\"] = ecl.apply(lambda row: np.rad2deg(row.long))\n",
    "    \n",
    "    # Return the updated dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "def galactic_coordinates(df):\n",
    "    # Define the lambda function to be applied to each row of the dataframe\n",
    "    gal = df.apply(lambda row: ephem.Galactic(ephem.Equatorial('%s' % (row.meanra / 15.),\n",
    "                                                               '%s' % row.meandec, epoch=ephem.J2000)), axis=1)\n",
    "    # Apply the function to each row, the result is append as a new column\n",
    "    df[\"gal_lat\"] = gal.apply(lambda row: np.rad2deg(row.lat))\n",
    "    df[\"gal_long\"] = gal.apply(lambda row: np.rad2deg(row.long))\n",
    "    \n",
    "    # Return the updated dataframe\n",
    "    return df\n",
    "\n",
    "# For each of our dataframe corresponding to one of the classes of the stamp classifier\n",
    "# we add the ecliptic and galactic coordinates\n",
    "for cl, df in objects.items():\n",
    "    ecl_df = ecliptic_coordinates(df)\n",
    "    gal_df = galactic_coordinates(ecl_df)\n",
    "    objects[cl] = gal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T16:00:08.362526Z",
     "start_time": "2022-11-04T16:00:08.358460Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "zLpigBuiDTK-"
   },
   "outputs": [],
   "source": [
    "def plot_spatial_distribution(df, ax, index=0, cmin_val=0.1, vmax_val=5, titles=\"\", fontsize=18, x_label=None, y_label=None):\n",
    "    dims = ['gal_long', 'gal_lat'] # Let's use our new column to plot the objects\n",
    "    # This is a 2D histogram of the positions of objects for each of the classes\n",
    "    _, _, _, im = ax.hist2d(df[dims].values[:, 0], df[dims].values[:, 1],\n",
    "                            (300, 300), cmap=\"viridis\", vmax=vmax_val, cmin=cmin_val)\n",
    "    ax.tick_params(axis='both', labelsize=fontsize-2)\n",
    "    ax.set_xlim([0, 360])\n",
    "    ax.set_ylim([-80, 80])\n",
    "    cbar = plt.colorbar(im,ax=ax, pad=0)\n",
    "    cbar.ax.tick_params(labelsize=fontsize-4)\n",
    "    \n",
    "    ecliptic_lat = np.zeros(500)\n",
    "    ecliptic_longi = np.linspace(0, 360, num=500)\n",
    "    # This auxiliary function computes the ecliptic plane by converting\n",
    "    # the ecliptic latitude 0 to galactic coordinates\n",
    "    # We should find many asteroids near the ecliptic\n",
    "    ecliptic = SkyCoord(ecliptic_longi, ecliptic_lat, unit='deg', frame='barycentrictrueecliptic')\n",
    "    galact_long, galact_lat = ecliptic.galactic.l.deg, ecliptic.galactic.b.deg\n",
    "    \n",
    "    ax.set_title(titles, fontsize=fontsize)\n",
    "    ax.plot(galact_long, galact_lat, \"ok\", markersize=6)\n",
    "    ax.plot(galact_long, galact_lat, \"oy\", markersize=4)\n",
    "    if not x_label is None:\n",
    "        ax.set_xlabel(x_label, fontsize=fontsize)\n",
    "    if not y_label is None:\n",
    "        ax.set_ylabel(y_label, fontsize=fontsize)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T16:00:09.644039Z",
     "start_time": "2022-11-04T16:00:08.944787Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 747
    },
    "colab_type": "code",
    "id": "nU9G3ahUDTLG",
    "outputId": "abf368ef-1e78-42af-d81f-565ecb20d5d0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(3*10, 2*6))\n",
    "fig.set_facecolor('white')\n",
    "plt.subplots_adjust(wspace=0.0, hspace=0.15)\n",
    "ax = ax.flatten() # A trick to iterate over the axis of a subplot array\n",
    "titles = [\"all objects\", ] + list(objects.keys())\n",
    "# This is just to control the saturation of the histograms, the larger\n",
    "# the number, the larger the amount of objects needed in the same location to increase the color scale\n",
    "max_count_per_class = dict(zip(titles, [20, 5, 5, 10, 5, 5])) \n",
    "\n",
    "for i in range(6):\n",
    "    x_label = None\n",
    "    y_label = None\n",
    "    if i == 0:\n",
    "        df = pd.concat(list(objects.values()), axis=0)\n",
    "    else:\n",
    "        df = list(objects.values())[i-1]\n",
    "    \n",
    "    if i in [0, 3]:\n",
    "        y_label = \"Galactic Latitude\"\n",
    "    if i in [3, 4, 5]:\n",
    "        x_label = \"Galactic Longitude\"\n",
    "    ax[i] = plot_spatial_distribution(df, ax[i], titles=titles[i], vmax_val=max_count_per_class[titles[i]], x_label=x_label, y_label=y_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxzDxTgRDTLL"
   },
   "source": [
    "Here us the spatial distribution for the unlabeled data, and distribution of predictions per class. The colorbar indicates the density of points. The ecliptic is shown with a yellow line with black edges. The distributions are shown as a 2d histogram of density of alerts. Extragalactic sources (SNe and AGNs) are found outside the Galactic plane. On the contrary, VS are concentrated in the Galactic plane. Asteroids are near the ecliptic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O1dBJhJ3DTLM"
   },
   "source": [
    "### Probabilities per class as a function of the position\n",
    "\n",
    "Even though most of the objects per class lie in a reasonable position according to their nature, there are some errors or contamination between classes. It is interesting to see how certain is the stamp classifier for each class depending on their position, so let’s plot the probability of each object belonging to each class in the same galactic coordinates projection. We only have to modify our previous “plot_spatial_distribution” function to make a scatter plot instead of the 2d histogram. We will fill each scatter dot with a colormap and size that reflects their probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T16:00:16.242039Z",
     "start_time": "2022-11-04T16:00:16.226839Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "xkz6OEGEDTLN"
   },
   "outputs": [],
   "source": [
    "def plot_spatial_probabilities(df, ax, index=0, cmin_val=0.1, vmax_val=5, titles=\"\", fontsize=18, x_label=None, y_label=None):\n",
    "    # We sort the rows of the dataframe first in order to reduces biases when \"painting\" the plot with the scatter\n",
    "    df = df.sample(frac=1) \n",
    "    dims = ['gal_long', 'gal_lat'] # Let's use our new column to plot the objects\n",
    "    # We will use the normalized probabilities (between 0 and 1) to scale the size of each dot according \n",
    "    # the their probability of belonging to the respective class\n",
    "    normalized_probabilities_per_class = df[\"probability\"].values - np.amin(df[\"probability\"].values)\n",
    "    normalized_probabilities_per_class = normalized_probabilities_per_class/np.amax(normalized_probabilities_per_class)\n",
    "    # Variable size dots for the scatter plot\n",
    "    variable_sizes = 10 + normalized_probabilities_per_class*100\n",
    "    color_map = plt.cm.get_cmap('viridis')\n",
    "    im = ax.scatter(df[dims].values[:, 0], df[dims].values[:, 1], c=df[\"probability\"].values, cmap=color_map,\n",
    "                   s=variable_sizes, alpha=0.7)\n",
    "    ax.tick_params(axis='both', labelsize=fontsize-2)\n",
    "    ax.set_xlim([0, 360])\n",
    "    ax.set_ylim([-80, 80])\n",
    "    cbar = plt.colorbar(im,ax=ax, pad=0)\n",
    "    cbar.ax.tick_params(labelsize=fontsize-4)\n",
    "    \n",
    "    ecliptic_lat = np.linspace(0, 0, num=500)\n",
    "    ecliptic_longi = np.linspace(0, 360, num=500)\n",
    "    # This auxiliary function computes the ecliptic plane by converting\n",
    "    # the ecliptic latitude 0 to galactic coordinates\n",
    "    ecliptic = SkyCoord(ecliptic_longi, ecliptic_lat, unit='deg', frame='barycentrictrueecliptic')\n",
    "    galact_long, galact_lat = ecliptic.galactic.l.deg, ecliptic.galactic.b.deg\n",
    "    \n",
    "    ax.set_title(titles, fontsize=fontsize)\n",
    "    ax.plot(galact_long, galact_lat, \"ok\", markersize=6)\n",
    "    ax.plot(galact_long, galact_lat, \"oy\", markersize=4)\n",
    "    \n",
    "    if not x_label is None:\n",
    "        ax.set_xlabel(x_label, fontsize=fontsize)\n",
    "    if not y_label is None:\n",
    "        ax.set_ylabel(y_label, fontsize=fontsize)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T16:00:18.181007Z",
     "start_time": "2022-11-04T16:00:17.360673Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 747
    },
    "colab_type": "code",
    "id": "dv_RD4x6DTLU",
    "outputId": "1827f3b6-e5ab-4f9d-a769-f4dae23e73f8"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(3*10, 2*6))\n",
    "fig.set_facecolor('white')\n",
    "plt.subplots_adjust(wspace=0.0, hspace=0.15)\n",
    "ax = ax.flatten() # A trick to iterate over the axis of a subplot array\n",
    "titles = [\"all objects\", ] + list(objects.keys())\n",
    "\n",
    "for i in range(6):\n",
    "    x_label = None\n",
    "    y_label = None\n",
    "    if i == 0:\n",
    "        df = pd.concat(list(objects.values()), axis=0)\n",
    "    else:\n",
    "        df = list(objects.values())[i-1]\n",
    "    \n",
    "    if i in [0, 3]:\n",
    "        y_label = \"Galactic Latitude\"\n",
    "    if i in [3, 4, 5]:\n",
    "        x_label = \"Galactic Longitude\"\n",
    "    \n",
    "    ax[i] = plot_spatial_probabilities(df, ax[i], titles=titles[i], vmax_val=max_count_per_class[titles[i]], x_label=x_label, y_label=y_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qiJ-otmNDTLa"
   },
   "source": [
    "For the SN class, the stamp classifier seems to be more confident about the prediction further from the ecliptic, there is a large blob of green-yellow dots at around (40, 120), while darker blobs near the ecliptic, meaning less confidence in the prediction. We can also see a greener blob near the center of the galaxy in the case of variable stars. In addition, it is also important to know the relative confidence between classes, some classes are harder to classify than others as you can see in the “all objects” scatter. Now, we will plot the distribution of probabilities per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T16:00:50.035781Z",
     "start_time": "2022-11-04T16:00:49.854953Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "colab_type": "code",
    "id": "O5fwnjc5DTLa",
    "outputId": "cddf7917-c365-46cd-c71b-f632b2a01b11"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "fig.set_facecolor('white')\n",
    "for i in range(6):\n",
    "    if i == 0:\n",
    "        df = pd.concat(list(objects.values()), axis=0)\n",
    "        h, bins = np.histogram(df.probability.values, bins=10, density=True)\n",
    "    else:\n",
    "        df = list(objects.values())[i-1]\n",
    "        h, bins = np.histogram(df.probability.values, bins=bins, density=True)\n",
    "    ax.plot(bins[:-1], h, label=titles[i])\n",
    "    \n",
    "plt.legend()\n",
    "ax.set_xlabel(\"Class probability\", fontsize=16)\n",
    "ax.set_ylabel(\"Freq\", fontsize=16)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MRC5O-X0DTLj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ALeRCE_ZTF_Stamp_Classifier_newDB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
